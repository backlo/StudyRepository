# ES 집계 및 캐시

### ES 집계의 특징

* 실시간에 가깝게 어떠한 대용량의 데이터를 처리하여 분석 결과를 내놓은 프로그램

* 집계 기능은 일반 검색 기능보다 훨씬 더 많은 리소스를 소모
  
  * 캐시를 활용해 해결
  
* example

  ```
  - request
  GET <인덱스명>/_search
  {
    "query": {
      … <쿼리 구문> …
    },
    "aggs": {
      "<임의의 aggregation 1>": {
        "<aggregation 종류>": {
          … <aggreagation 구문> …
        }
      },
      "<임의의 aggregation 2>": {
        "<aggregation 종류>": {
          … <aggreagation 구문> …
        }
      }
    }
  }
  
  -response
  {
    "hits": {
  			… 쿼리 결과 (hit 된 도큐먼트 내용) …
    },
    "aggregations": {
      "<임의의 aggregation 1>": {
  				… aggregation 결과 …
      },
      "<임의의 aggregation 2>": {
  				… aggregation 결과 …
      }
    }
  }
  ```

  



### 캐시 종류

> 엘라스틱서치의 캐시를 이용하면 질의의 결과를 캐시에 두고 다음에 동일한 요청이 오면 다시 한번 요청을 처리하는 것이 아닌 캐시에 있는 결과값을 그대로 돌려주는 기능

* 특징
  * 보통 캐시의 크기는 일반적으로 힙 메모리의 1% 정도로 할당
  * 캐시에 없는 질의의 경우 성능 향상에 별다른 도움이 되지 못함
* 종류
  * 노드 쿼리 캐시 
    * 노드의 모든 샤드가 공유하는 LRU캐시
    * 캐시 용량이 가득차면 사용량이 가장 적은 데이터를 삭제하고 새로운 결과값을 캐싱
    * 쿼리 캐싱 사용여부는 elasticsearch.yml 파일에 아래 옵션을 추가
    * 기본값은 true
      * Index.queries.cache.enabled: true
  * 샤드 리퀘스트 캐시
    * 샤드에서 수행된 쿼리의 결과를 캐싱
    * 샤드의 내용이 변경되면 캐시도 삭제하기 때문에 문서 수정이 빈번한 인덱스에서는 오히려 성능 저하를 일으킴
  * 필드 데이터 캐시
    * 엘라스틱서치가 필드에서 집계 연산을 수행할 때는 모든 필드 값을 메모리에 로드
    * 계산되는 집계 쿼리는 성능적인 측면에서 비용이 상당
    * 필드 데이터 캐시는 집계 계산 동안 필드의 값을 메모리에 보관



### 매트릭 집계

> 숫자, 또는 날짜 필드의 값을 가지고 계산하는 집계

* 합산, 평균, 최소값, 최대값, 개수 집계
  * 최대, 최소, 합, 평균값을 가지고 오는 집계
  * script를 사용하여 후처리를 할 수 있음
* 통계 집계
  * 위 집계를 전체 나타내주는 집계
  * count까지 나와 집계 데이터 총량을 나타내줌
* 카디널리티 집계
  * 필드의 값이 모두 몇 종류인지 분포값을 알기 위한 집계
  * Text 필드에는 사용할 수 없음
  * 중복 된 값을 제외한 고유한 값에 대한 집계를 수행
    * 하지만 모든 문서에 대해 중복된 값을 집계하는 것은 성능에 큰 영향을 줄 수 있기에 근사치를 통해 집계
    * 근사치를 구하기 위해 HyperLogLog++ 알고리즘 기반으로 동작

* 백분위 집계
  * 값들을 백분위 별로 보기 위해서 사용하는 집계
  * 근사치이고 TDigest 알고리즘을 이용
  * 문서들의 집합 크기가 작을수록 정확도는 높아지고, 문서의 집합이 클수록 오차 범위가 늘어남
  * percents 옵션을 상요해서 백분위 구간을 지정 가능
* 백분위 수 랭크 집계
  * 특정 값을 주고 어느 백분위 범위에 속하는지 결과값으로 돌려주는 집계
* 지형 경계 집계
  * 지형 좌표를 포함하고 있는 필드에 대해 해당 지역 경계 상자를 계산하는 집계
  * 사용하려면 필드 타입이 geo_point여야 함

* 집계 scope

  * 쿼리라는 필드가 있는데 쿼리를 통해 나온 결과값을 이용해 집계를 내겠다는 의미
  * 집계 대상이 되는 Scope를 Query를 이용하여 지정
  * 참고로 쿼리 필드가 생략되면 내부적으로 match_all 쿼리를 수행
  * global - aggs
    * 상위 집계를 수행하고 이외로 전체 집계를 한번 더 수행
  * Score 점수
    * 어떠한 검색의 정확도를 나타내기 위해 표시해 주는 필드 - 여러 알고리즘을 사용 (최근 버전 BM25)
    * 스코어 점수가 필요없는 어떠한 검색에 constant_score 쿼리를 사용하면 성능상 이슈가 있음
      * 자주 사용되는 필터 쿼리는 엘라스틱 서치에 캐시하므로 성능에 이점이 있을 수 있음



### 버킷 집계

> 버킷을 생성하는 집계

* 생성되는 버킷은 쿼리와 함께 수행되어 쿼리 결과에 따른 컨텍스트 내에서 집계가 이루어짐
* 하위집계를 사용해 집계된 버킷 결과에 하위 집계 수행이 가능



#### 특징

* 너무 많은 하위 집계를 해버리면 메모리 사용량을 점점 높히기 때문에 성능에 악영향을 줄 수 있음

  * 이러한 문제 때문에 ES 설정으로 최대 버킷수를 조정할 수 있음

* Search.max_buckets

  * -1혹은 10000 이상의 값을 지정할 경우 ES에서 경고 메세지를 보냄
  * 안정적인 집계 분석을 위해 버킷의 크기, 집계의 중첩양 등을 충분히 고려한 후에 집계 수행을 해야함

* 범위 집계

  * 사용자가 지정한 범위 내에서 집계를 수행하는 다중 버킷 집계

  * 집계 수행 -> 쿼리의 결과가 범위에 해당하는지 확인 -> 범위에 해당되는 문서들에 대해서만 집계를 수행

  * from, to 속성을 지정하고, to에 지정한 값을 결과에서 제외

  * Key 속성을 사용해 의미있는 값으로 지정해 줄 수 있음 

    ```
    req
    { "key":"small","from":1000,"to":2000 }
    
    res
    { "key": "small", "from": 1000.0, "to": 2000.0, "doc_count": 754 },
    ```

* 날짜 범위 집계

  * 날짜 값을 범위로 집계 수행

* 히스토그램 집계

  * 지정한 범위 간격으로 집계

* 날짜 히스토그램 집계

  * 날짜 히스토그램 집계는 분, 시간, 월, 연도를 구간으로 집계를 수행

* 텀즈 집계

  * 동적으로 생성하는 다중 버킷 집계

  * 집계시 지정한 필드에 대해 빈도수가 높은 텀의 순위로 결과가 반환

  * Keyword 데이터 타입을 사용해야 성능을 보장

    * Test 타입의 경우 형태소 분석때문에 성능이 최악

  * doc_count_error_upper_bound

    * 문서 수에 대한 오류 상한선

    * 오류 상한선이 있는 이유? -> 각 샤드별로 계산되는 집계의 성능을 고려해 근사치를 계산하기 때문에 문서 수가 정확하지 않아 최대 오류 상한선을 보여줌

    * example - 청크 분포

      |      | 샤드 A | 샤드 B | 샤드 C |
      | ---- | ------ | ------ | ------ |
      | 1    | A(25)  | A(30)  | A(45)  |
      | 2    | B(18)  | B(25)  | C(44)  |
      | 3    | C(25)  |        |        |

      * 집계 사이즈 2로 지정하면 `A -> 100`, `B -> 43`, `c -> 44`  오차가 생겨버림
      * 따라서 size값을 지정해서 오차를 줄이거나, 전부 포함 시켜야 함
      * 여기서 doc_count_error_upper_bound 값은 25

  * sum_other_doc_count

    * 결과에 포함되지 않은 모든 문서수

* 집계와 샤드 크기

  * 텀즈 집계가 수행되면 각 샤드에게 최상위 버킷을 제공하도록 요청한 후, 모든 샤드로부터 결과를 받을 때까지 대기
  * 결과를 기다리다가 모든 샤드로 부터 결과를 받으면 설정된 size에 맞춰 하나로 병합한 후 결과를 반환
  * 각 샤드는 size에 해당되는 갯수로 집계 결과를 반환하지 않음
  * 각 샤드에서는 정확성을 위해 샤드 크기를 이용한 경험적인 방법을 사용해 내부적으로 집계를 수행
  * 텀즈 집계 결과로 받을 텀의 개수를 정확하게 파악할 수 있는 경우에는 shard_size 속성을 사용해 각 샤드에서 집계할 크기를 직접 지정해 불필요한 연산을 줄이면서 정확도를 높일수 있음



### 파이프 라인 집계

> 쿼리 조건에 부합하는 문서에 대해 집계를 수행하는 것이 아니라, 다른 집계로 생성된 버킷을 참조해서 집계를 수행



#### 특징

* 집계 또는 중첩된 집계를 통해 생성된 버킷을 사용해 추가적으로 계산을 수행
* 부모, 형제라는 두가지 유형이 존재
* 파이프라인 집계를 수행할 때는 bucket_path 파라미터를 사용하여 참조할 집계의 경로를 지정함으로써 체인 형식으로 집계간 연산을 수행
* 파이프라인 집계는 모든 집계가 완료된 후에 생성된 버킷을 사용하기 때문에 하위 집계를 가질 수 없음



#### 종류

* 형제 집계
  * 동일 선상의 위치에서 수행되는 새 집계를 의미
  * 즉 형제 집계를 통해 수행되는 집계는 기존 버킷에 추가되는 형태가 아닌 동일 선상의 위치에서 새 집계가 생성
  * 종류
    * 평균 - 지정된 메트릭의 평균 값을 계산하는 파이프라인 집계
    * 최대 - 최대 값으로 버킷을 식별하고 버킷의 값과 키를 출력하는 파이프 라인 집계
    * 최소 - 최소 값으로 버킷을 식별하고 버킷의 값과 키를 출력하는 파이프 라인 집계
    * 합계 - 지정된 메트릭의 합을 계산하는 파이프라인 집계
    * 통계 - 모든 버킷에 대한 다양한 통계를 계산하는 파이프라인 집계
    * 확장 - 모든 버킷에 대한 다양한 통계를 계산하는 파이프라인 집계 (제곱합, 표준편차 등 제공)
    * 백분위수 - 모든 버킷에서 백분위 수를 계산하는 파이프라인 집계
    * 이동 평균 - 순차 데이터를 부드럽게하는 간단한 파이프라인 집계, 일반적으로 주가 또는 서버 메트릭과 같은 시간 기반 데이터에 적용
* 부모 집계
  * 집계를 통해 생성된 버킷을 사용해 계산을 수행하고, 그 결과를 기존 집계 결과에 반영
  * 종류
    * 파생집계 - 위 히스토그램 집계에서 지정된 메트릭의 미분을 계산하는 상위 파이프 라인 집계
    * 누적집계 - 위 히스토그램 집계에서 지정된 지표의 누적 합계를 계산한는 파이프 라인 집계
    * 버킷 스크립트 집계 - 부모 다중 버킷 집계에서 지정된 메트릭에 대해 버킷 당 계산을 수행 할 수 있는 스크립트를 실행하는 부모 파이프라인 집계
    * 버킷 셀렉터 집계 - 현재 버킷을 상위 멀티 버킷 집계에 유지할지 여부를 결정하는 스크립트를 실행하는 상위 파이프 라인 집계
    * 시계열 차분 집계 - 시계열의 값을 다른 시차 또는 기간에 차감하는 기술



