## ES 성능 극대화

ES 성능 향상에는 유스케이스, 하드웨어, 설정에 따라 달라진다. 언제나 성능향상에는 상응하는 대가가 따르기 때문에 무엇을 먼저 희생을 해야 할지 결정해야한다.

* 유스케이스
  * 애플리케이션 복잡도 - 그룹화
    * HTTP 요청을 그룹화하면서 성능을 극대화
    * 네트워크 비용이 작음
  * 색인과 검색 중 어느 하나의 성능 초점
    * 루씬 세그먼트를 어떻게 관리하는지가 관건
    *  Refresh, flush, merge 정책, 저장 정책에 대한 설정이 어떻게 동작하고 이들이 검색과 색인 성능에 어떤 영향을 미치는지 알아보는게 중요
    * 종종 색인 성능이 높으면 검색 성능이 낮고, 반대로 검색이 높으면 색인이 낮을때가 있음
  * 메모리
    * 캐싱을 잘 사용하면 성능 향상에 도움이 됌
    * 필터 캐시와 어떻게 그것을 적절히 사용할 수 있는지에 대해 알아보는 것이 중요
    * 샤드 쿼리 캐시에 대해서도 알아보고 엘라스틱서치가 충분한 힙 공간을 사용하면서도 동시에 운영체제가 색인을 캐싱하기 위해 충분한 공간을 남겨 놓는 법에 대해서 알아보는 것도 중요
    * 준비되지 않은 캐시에 대해 검색 요청이 지나치게 느리게 수행된다면, 색인 워머를 통해 쿼리를 백그라운드에서 실행시켜 캐시를 미리 준비 시켜 놓을 수 있음
  * 유스케이스에 따라서 색인 시점에 텍스트를 분석하는 방법이나 사용하는 쿼리의 종류는 더 복잡한 것이어서 다른 작업을 느리게 하거나 메모리를 더 많이 사용할 수 있음
  * 색인 시점에서 더 많은 텀을 생성할 것인가, 혹은 검색 시점에 더 많은 텀들에 찾아볼 것인가, 스크립트 이점을 활용할 것인가, 깊은 페이징은 어떻게 처리할것인가 등을 생각해 봐야함



### 요청 그룹화 하기

#### 1. Bulk API

1. 색인 성능을 높이기 위해서 여러 문서를 하나의 벌크 API로 색인 요청하면 성능 향상
2. 네트워크 오버헤드가 줄어들어 더 많은 색인 처리량을 확보
3. 하나의 벌크는 색인과 관련된 모든 동작을 포함할 수 있음
   * 예를 들어 하나의 벌크에서 문서를 생성하거나, 수정, 삭제가 가능
   * 또한 Bulk API는 색인만 사용되는게 아니라 다른 곳에서도 사용 가능
   * 만약 애플리케이션 다수의 조회 혹은 검색 요청을 보내야 한다면, 이것을 벌크 요청인 멀티겟이나 멀티 서치 API도 존재
4. 특정 문서가 색인에 실패한 경우, 전체 벌크가 실패한 것을 의미하지 않음
   * 한 벌크에 있는 항목들 끼리는 서로 독립적
   * 즉 한 응답만이 아닌 각각의 작업에 대한 응답을 받을 수 있는 것도 이 때문
   * 사용자는 어플리케이션에 JSON 응답을 통해 어떤 작업이 성공하고 실패했는지 확인 가능
5. 성능 관점에서 벌크 사이즈는 매우 중요
   * 벌크가 지나치게 크면 과다하게 메모리 사용하고 벌크가 너무 작으면 네트워크 오버헤드 발생
   * 최적점은 문서 크기와 클러스터의 성능에 따라 달라짐 - 클러스터가 크고 장비가 좋으면 벌크와 검색을 빠르게 수행
   * 테스트로 자신의 유스케이스에 맞는 최적의 벌크 사이즈를 찾아야 함



#### 2. 일반 색인 vs 벌크 색인

|               | 일반                                    | 벌크                                         |
| ------------- | --------------------------------------- | -------------------------------------------- |
| 네트워크 비용 | 많음                                    | 적음                                         |
| APP 응답 처리 | 엘라스틱 서치의 응답을 매번 기다려야 함 | 한번에 색인하면 응답을 매번 기다릴 필요 없음 |
| ES 요청 처리  | 요청 마다 모든 데이터를 처리            | 한꺼번에 요청을 처리 가능                    |



#### 3. Index Mapping

* Mapping Type- [참고](https://gintrie.tistory.com/47)

  * SQL 데이터베이스에 비유하면 테이블과 같은 개념

  * 7.0 부터 사라짐 - [참고](https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html)
  * 도큐먼트 타입 별 인덱스를 사용해서 매핑 타입을 해결 (user -> user index , tweet -> tweet index 색인)
    * 루쎈의 압축 기술을 효과적으로 사용 가능

* document id
  * 색인하고자 하는 문서의 id를 나타내줌
  * 생략할 경우 엘라스틱 서치가 자동으로 ID 생성
  * 로그성 데이터 같은 경우 본질적으로 primary 값을 가지고 있지 않고 직접 찾아볼 필요가 없기 때문에 ID를 생략해도 괜찮음



#### 4. 멀티 서치와 멀티 GET API

> 다수의 검색이나 조회 요청 할 시 하나로 묶어서 사용 - 네트워크 레이턴시 비용을 줄여줌

1. 멀티 서치 - 다수의 검색 요청을 하나로 보내어 여러 종류의 문서를 검색 할 수 있음
   1. _msearch를 사용
   2. 여러 인덱스를 두어 검색이 가능
2. 멀티 겟 - 외부 프로세스에서 검색은 수행하지 않고 다수의 문서를 조회할 필요만 있을 때 유용
   1. 모든 ID가 index가 같은경우 ID 배열에 ID값들을 입력할 것을 권장 ( "ids" : [ "1", "2" ] )
3. 멀티 서치와 멀티 겟은 벌크 API와 마찬가지로 테스트를 통해 성능 최적화 해야함



### 루씬의 세그먼트 관리를 최적화 하기

* ES는 저장할 문서를 전달 받으면 이를 먼저 메모리에 있는 세그먼트라는 역색인에 담음
* 이 세그먼트는 이따금씩 디스크로 이동
* 이 세그먼트는 운영체제가 쉽게 캐싱할 수 있도록 하기 위해 삭제만 가능할뿐 변경이 불가
* 또한 작은 역색인을 병합하고 검색을 빠르게 하기 위해 주기적으로 큰 세그먼트로 생성되어 합쳐짐
* 세그먼트 관리 방법에 따라 성능이 향상
  * 얼마나 자주 리프레시와 플러시를 수행할 것인가 - 성능 이득을 훨씬 많이 봄
    * 리프레시 : 엘라스틱서치의 색인에 대한 뷰를 갱신, 새로 색인된 데이터가 검색 될 수 있도록 함
    * 플러쉬 : 색인된 데이터를 메모리에서 디스크로 커밋
  * 머지 정책
    * 루씬 데이터는 불변 파일의 형태로 저장
    * 더 많은 데이터를 색인할수록 더 많은 세그먼트가 생성
    * 여러 세그먼트에 걸친 검색은 느리므로, 작은 세그먼트들을 백그라운드에서 큰 세그먼트들로 머지하여 세그먼트 수를 관리
    * 머지는 성능 집약적인 작업으로 특히 I/O를 많이 사용
    * 머지 정책을 조정하여 머지의 빈도나 세그먼트의 최대 크기를 조절
  * 저장과 저장 제한
    * 엘라스틱서치는 머지 작업이 시스템의 I/O에 미치는 영향을 초당 일정 바이트로 제한가능
    * 사용자의 하드웨어 유스케이스에 따라, 이 값을 조절 가능
    * 여러 옵셩ㄴ을 통해 ES가 어떻게 저장소를 사용할게 만들지 조절 가능



#### 1. 리프레시와 플러시 임계값

* ES는 가장 최근에 색인한 데이터가 아닌 그에 근접한 데이터에 대해서 수행하기 때문에 준 실시간성 특성을 가짐

* 따라서 엘라스틱서치가 색인에 대한 현재 시점의 뷰를 유지하고 있기 때문에, 다수의 검색이 같은 파일을 탐색하고 같은 캐시를 재사용함

* 즉 리프레시가 되기 전까지는 새로 색인된 데이터는 검색이 가능하지 못함

* 리프레시의 장단점

  * 장점
    * 새로 색인된 데이터를 검색할 수 있음
  * 단점
    * 리프레시로 인한 성능 비용이 큼
    * 일부 캐시는 무효화되어 검색이 느려지고, 이를 다시 갱신하는 작업은 더 많은 프로세싱 파워를 필요로 하여 색인을 느려지게 함

* 언제 리프레시 할 것인가

  * Refresh_interval를 증가시킬수록 색인 처리량은 늘어남
    * 이는 리프레시에 시스템 자원을 덜 사용하기 때문
    * -1 값을 두고 수동으로 리프레시를 할 수 있음
  * 배치를 통해 주기적으로 변경이 일어나는 경우 리프레시 값을 크게 하면 색인 처리량이 향상되기 때문에 이런 상황에서 적합
  * 수동으로 리프레시 하고 싶으면 -> ``GET /index_name/_refresh``

* 언제 플러시를 할 것인가

  * ES에서 리프레시 작업과 메모리 내의 세그먼트를 디스크로 커밋하는 것은 별개 - 리프레시 한다고 세그먼트를 디스크로 커밋하지 않음

  * 메모리 내의 세그먼트를 디스크 내의 실제 루씬 색인으로 커밋하는 것을 플러시라고 함

  * 이 작업은 세그먼트가 검색 가능한지 여부와 무관하게 발생

  * 그렇다면 플러시는 언제 사용할까

    * 메모리 버퍼가 가득 찼을때
    * 마지막 플러시로부터 일정 시간이 지났을 때
    * 트랜잭션 로그와 사이즈가 일정한 임계치를 넘었을 때
      * 트랜잭션 로그 - 노드 장애나 샤드 재배치로 인해 메모리 내의 데이터가 유실 되지 않도록 보장하기위해, 플러시 되지 않은 색인 요청들을 트랜잭션 로그에 기록

  * 즉 위에 3가지 설정값을 조정해야 함

    * 메모리 버퍼 크기 : ``elasticsearch.yml``에 들어가 ``indices.memory.index_buffer_size`` 값을 통해 지정, 이 값을 통해 노드 전체의 버퍼 크기를 조절 가능

    * 트랜잭션 로그 설정 - 밑과 같이 설정 가능

      ```
      PUT index_name/_settings
      { 
      	"index.translog": { 
      		"flush_threshold_size": "500mb", // 플러시를 발생시키게 될 크기
      		"flush_threshold_period": "10m" // 마지막 플러시로부터의 시간 간격
      	} 
      }
      ```

  * 플러시가 수행되면 하나 이상의 세그먼트가 디스크에 생성 -> 쿼리를 수행하면 ES는 모든 세그먼트를 조회하고 결과를 샤드의 전체 응답에 포함 -> 샤드별 응답들은 전체 응답으로 집계되어 사용자 APP에 반환

  * 여기서 중요한 점은 검색해야 할 샤드의 수가 많을 수록 검색이 느려짐 -> 샤드의 숫자를 일정 수준으로 유지하기 위해서 ES는 백그라운드에서 다수의 작은 세그먼트들을 큰 세그먼트로 병합



#### 2. 머지와 머지 정책

* 세그먼트는 불변 파일들의 집합으로 ES가 색인된 데이터를 저장하기 위해 사용

* 세그먼트는 불변이기 때문에 쉽게 캐싱이 되고, 검색을 더 빠르게 수행 가능

* 문서를 갱신하는 것은 실제 해당 문서를 갱신하는 것이 아닌 새 문서를 하나 더 색인하는 것 -> 기존의 문서를 삭제

* 삭제의 경우 세그먼트에서 실제로 문서를 삭제하는 것이 아닌 .del파일에 지워졌다고 표시를 남김

* 즉 문서들은 세그먼트 머지 작업을 통해 백그라운드에서 실제로 삭제 작업을 수행

* 세그먼트 머지 목적

  * 세그먼트의 총 숫자를 적절하게 유지 <- 이를 통한 쿼리 성능 향상
  * 삭제된 문서들을 제거

* 계층적 정책 - 기본 머지 정책

  1. 플러시 작업은 너무 많아지기 전까지 첫번째 계층에 세그먼트들을 추가한다. 너무 많은 것이 4개라고 해본다.
  2. 작은 세그먼트들은 큰 세그먼트로 합쳐진다. 플러시는 계속 새로운 작은 세그먼트들을 생성한다.
  3. 결국, 다음 계층에는 네 개의 세그먼트가 있게 된다.
  4. 네 개의 큰 세그먼트들은 더 큰 세그먼트로 합쳐지고, 이런 절차가 반복된다.
  5. 계층 내에서 임계치에 도달할 때까지 반복된다. 상대적으로 작은 세그먼트만이 병합되고, 최대 세그먼트들은 그대로 남아 있다.

* 머지 관련 옵션 튜닝

  * 머지의 전체적인 목적은 I/O와 CPU 시간을 조금 희생하여 검색 성능을 높이는데 있음
  * 머지는 문서를 CUD를 동시에 발생하기 때문에 머지가 많을 수록 이런 작업들에 대한 비용이 커짐
  * 반대로 빠른 색인을 원한다면, 머지를 덜 함으로써 검색 성능을 조금 희생하기를 원할 것임

  ```
  get-together/_settings {
  	"index.merge": { 
  		"policy": { 
  			"segments_per_tier": 5, // 이 값이 클수록, 하나의 계층에서 더많은 세그먼트를 가질수있음(더 적은 머지 작업 수행, 향상된 색인)
  			"max_merge_at_once": 5, // 이 값을 통해 한번에 합쳐질 수 있는 세그먼트 수를 제한. 보통 segments_per_tier로 대신 조절
  															// segments_per_tier 값 보다 크면 지나치게 많은 머지 작업이 발생
  			"max_merged_segment": "lgb" // 세그먼트 크기의 최댓값을 지정, 이 값보다 큰 세그먼트는 다른 세그먼트와 합쳐지지 않음
  																	// 머지 작업을 줄이고 빠른 색인을 원한다면 이 값을 낮춰 머지작업을 어렵게 함
  		}, 
  		"scheduler.max_thread_count": 1 // 백그라운드의 별도의 쓰레드에서 수행되는 머지 작업 스레드의 최대 갯수를 조절
  																 // CPU, I/O가 좋으면 값을 높여 적극적인 머지 정책을 가져가고, 반대로 느리면 이 값을 낮춰야함
  	} 
  }
  ```

* 색인 최적화

  * 강제 머지 요청 - 리프레시나 플러시처럼 머지 작업을 직접 실행하는 요청

    * 보통 이 작업은 검색을 빠르게 하기 위해 더이상 변하지 않을 색인에 실행하여 세그먼트 개수를 적게 만듬 (세그먼트수가 적으면 검색이 빠름)

  * 로그성 데이터 같은 경우 색인을 최적화 하여 세그먼트 갯수를 적게 만들어 검색 성능에 도움이 되게 만듬 (캐싱 리로딩)

  * 강제 머지 설정

    ```
    /index_name/_optimize?max_num_segments=1 // 샤드별로 몇개의 세그먼트로 병합되기를 원하는지
    ```

    

#### 3. 저장과 저장 제한

*  ``indices.store.throttle.max_bytes_per_sec`` - 저장 제한을 통해 머지 작업이 사용할 수 있는  I/O 처리량 제한 값 설정

  * 기본값은 20MB
  * 빠른 장비들을 가지고 있고 색인이 굉장히 많이 발생하고 있다면 CPU, I/O가 머지를 따라 잡지 못할 수 있음 -> 따라서 저장 제한을 200MB까지 높여야 할 것임

> 추가적으로 찾아보기





### 캐시 최적화

* ES의 캐싱이라는 기능으로 인해 보통의 하드웨어를 가지고 수십억건의 문서에 대한 검색을 1초 이내에 수행
* 필터와 쿼리를 혼합해서 사용하고 있다면, 필터 캐시는 검색을 빠르게 처리하는 데 있어 매우 중요한 역할을 하게 됌



#### 1. 필터와 필터 캐시

* 필터는 캐싱이 되기 때문에 사용을 권장
* 엘라스틱서치 2.0은 기본 동작으로 ``자주 사용되는 필터와 큰 세그먼트``에 대해 수행되는 필터만 캐싱
  * 이는 지나치게 적극적인 캐싱을 방지하면서 동시에 자주 사용되는 필터를 기억하고 최적화 진행

* 필터 캐시
  * 캐시될 필터의 결과는 필터 캐시에 저장
    * 해당 캐시는 노드 레벨에서 할당
    * 필터를 자주 사용하고 캐싱한다면, 캐시 필터 사이즈를 늘려야 함
    * ``indices.cache.filter.size: 30%`` 이러식으로 변경 가능
  * 캐시는 ES가 LRU 정책에 의해 사용된지 오래된 캐싱 항목을 제거하고 공간을 확보
  * ``index.cache.filter.expire``를 통해 필터 캐시를 만료 시킬 수 있음
    * 매번 검색할 때마다 기존의 캐시를 축출하고 새로운 캐시를 집어넣기 위한 상황에서 CPU 자원을 많이 소모하기 때문에 이러한 유스케이스에 효과적
* 필터 결합
  * 필터를 서로 결합시켜 원하는 결과를 내고 싶을 때 사용
  * 엘라스틱 서치의 비트셋을 사용하여 어떤 문서가 필터에 매치되는지 여부를 알기 위해 사용 (term, range 등)
  * 비트셋을 사용하지 않는 필터의 경우 _cache를 true로 설정하여 바로 결과값을 캐싱하도록 할 수 있음
  * 비트셋 캐싱 vs 단순한 결과 캐싱
    * 비트셋은 크기가 작고 쉽게 만듬 -> 필터가 처음 수행될 때 캐시를 생성하는 오버헤드가 매우 작음
    * 비트셋은 각 필터별로 저장 -> 예를 들어 서로 다른 두 쿼리에서 같은 텀 필터를 사용할 경우, 그 텀에 대한 비트셋은 재사용 가능
    * 비트셋은 다른 비트셋과 쉽게 결합해서 사용 가능 -> 비트셋을 사용하는 두쿼리를 사용할 경우, 쉽게 ES에게 AND, OR 비트 연산을 수행하도록 하여 어떤 문서가 결합된 조건에 매칭되는지 알아 낼 수 있음
  * 비트셋의 장점을 활용하기 위해서는 AND, OR 비트 연산을 bool 필터내에서 결합해야 함
  * 비트셋을 사용하는 필터와 그렇지 않은 필터를 함께 사용하는 경우 bool 필터에서 비트셋을 사용하는 것들을 결합하고 해당 필터를 다른 비트셋을 사용하지 않는 필터들과 함께 and/or/not 필터에 포함시킬 수 있음
  * 여기서 중요한건 and, or, not, bool 어느 필터에서 결합하든지 간에 필터가 수행되는 순서가 매우 중요
    * 텀 필터와 같이 비용이 작은 필터가 스크립트 필터처럼 큰 필터보다 앞에 위치해야함 - 그래야 비용이 큰 필터를 이전의 필터에 매치된 ㅈ더 작은 문서의 집합에 대해 수행
* 필드 데이터에 필터를 수행하기
  * 필드 데이터는 문서가 어떤 텀들에 매핑되는지를 저장하고 있는 메모리 내의 자료구조
  * 텀이 어떤 문서에 매핑되는지에 관한 것인 역 색인에 정반대의 것
  * 메모리를 사용하는 필드데이터에 대한 대안책은 doc value가 있음
    * doc value는 색인 타임에 연산되어 색인과 함께 디스크에 저장
    * Doc value는 수치 혹은 분석하지 않은 문자열 필드에서 동작
    * ES 2.0의 경우 이런 필드들에 대해 doc value를 기본으로 사용하는데 그 이유는 필드 데이터를 JVM힙에 들고 있는 것으로 얻을 수 있는 성능 이득에 비해서 비용이 큼
* 정리 
  * 필터 캐시에 캐싱하고 이는 필터가 재사용될 경우 매우 좋음
  * 재사용되지 않는다면 캐싱하지 않음
  * 텀즈와 범위 필터를 필드 데이터 위에서 수행하는 이를 위한 필드 데이터가 이미 로딩되어 있고 많은 텀을 사용할 경우 좋음



#### 2. 샤드 쿼리 캐시

* 샤드 쿼리 캐시는 샤드 레벨에서 요청 전체와 이에 대한 결과를 갖음

* 만약 샤드와 같은 요청에 대해 이미 응답을 했으면, 캐시로부터 이 요청을 처리할 수 있음

* 샤드 쿼리 캐시는 search_type, count인 경우에만 효과적

* ES 2.0에서는 size = 0으로 설정하여 캐싱을 수행할 수 있고, search_type=count의 형태는 더이상 지원 x

* 다른 텀에 대해서 검색하거나 아주 조금 다른 집계를 수행한 경우 샤드 쿼리 캐시가 사용되지 않음

  * 또한 리프레시가 발생하여 샤드의 내용이 변경되었으면 모든 샤드 캐시 쿼리는 무효화가 됌 - 그렇지 않으면 새로 매치되는 문서들이 색인에 추가 되었을 수 있으므로 캐시로부터 잘못된 응답을 받기 때문에 

* 따라서 샤드가 잘 변하지 않고 같은 요청이 반복적으로 된다면 샤드 쿼리 캐시를 사용하는 가치가 있음

  * 예를 들어 시계열 색인에 로그를 색인하고, 잘 변하지 않는 오래된 색인이 지워지기 전까지 자주 다수의 반복적인 집계를 수행하면 샤드 쿼리 캐시가 좋음

* 설정
  ```
  /index_name/_settings 
  { 
  	"index.cache.query.enable": true 
}
  ```
  
* ``indices.cache.query.size`` 를 조절하여 사이즈의 임계값을 설정 가능



#### 3.  JVM 힙과 운영체제 캐시

* ES가 어떤 요청을 처리할 충분한 힙을 가지고 있지 않다면 메모리 부족 오류를 발생 시킴
* 이는 노드 장애로 이어져 클러스터로 부터 떨어져 나가게 될 것 -> 다른 노드에도 부담이 증가 -> 레플리카를 재복사하기 때문에 보통 동등한 스팩의 노드를 두기 때문에 과부하가 일어남 -> 결국 다른 노드도 터짐 -> 전체 클러스터가 중단
* GC가 너무 자주 발생하면, GC 튜닝을 시도
  * GC가 CPU 자원을 과도하게 소모하고 있다면, 힙 사용률을 감소 시켜야함
    * 색인 버퍼의 크기를 줄임
    * 필터 캐시와 샤드 쿼리 캐시의 크기를 줄임
    * 검색과 집계 사이즈 파라미터 값을 줄임
    * 만약 사이즈 값을 사용한다면 데이터 노드도 아니고 마스터 노드도 아닌 노드를 클라이언트처럼 사용할 수 있음. 이 노드는 검색과 집계의 샤드별 결과를 종합하여 집계하는 역할

* 또다른 방법으로 전체 힙 대비 서바이버 영역을 늘리거나 혹은 영 영역을 늘려 모니터링을 통해 확보



 On-off

플래그 값이 y이면 네이버 쇼핑 상품이 노출 n이면 노출이 안됨

상품이 품절이 됐거나 이런것들 y/n 판단 모듈

카프카 큐에대한 수집 -> 컨슘해서 -> 서비스가 y로 가는지 n가는지 결정을 해주는 역할

